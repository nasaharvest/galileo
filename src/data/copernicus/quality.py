"""Quality control utilities for Copernicus satellite data.

This module provides functions for quality assessment and masking of satellite imagery,
particularly cloud masking for Sentinel-2 optical data.
"""

import tempfile
import zipfile
from pathlib import Path
from typing import Optional

import numpy as np
import rasterio


def extract_cloud_mask(zip_file_path: Path) -> Optional[np.ndarray]:
    """Extract cloud mask from Sentinel-2 Scene Classification Layer (SCL).

    WHAT IS THE SCL BAND:
    The Scene Classification Layer (SCL) is a quality band included with Sentinel-2
    Level-2A products. It classifies each pixel into categories like cloud, shadow,
    vegetation, water, etc. This is generated by the Sen2Cor atmospheric correction
    algorithm.

    WHY CLOUD MASKING MATTERS:
    Clouds obscure the ground and make optical imagery unusable for analysis.
    Cloud masking allows you to:
    - Identify which pixels contain valid ground observations
    - Exclude cloudy pixels from analysis
    - Find the clearest images in a time series
    - Create cloud-free composites by combining multiple images

    SCL CLASSIFICATION VALUES:
    The SCL band uses integer values to classify each pixel:
    - 0 = No Data (missing or invalid)
    - 1 = Saturated or defective pixel
    - 2 = Dark area (very low reflectance, topographic shadow)
    - 3 = Cloud shadow
    - 4 = Vegetation (CLEAR - keep this)
    - 5 = Not vegetated (bare soil, rock) (CLEAR - keep this)
    - 6 = Water (CLEAR - keep this)
    - 7 = Unclassified
    - 8 = Cloud medium probability (MASK OUT)
    - 9 = Cloud high probability (MASK OUT)
    - 10 = Thin cirrus (high altitude ice clouds) (MASK OUT)
    - 11 = Snow or ice (usually MASK OUT, depends on application)

    MASKING STRATEGY:
    We create a binary mask where:
    - 1 (True) = Clear pixel, safe to use (classes 4, 5, 6)
    - 0 (False) = Problematic pixel, should be masked (clouds, shadows, etc.)

    Args:
        zip_file_path: Path to Sentinel-2 Level-2A ZIP file
                      Note: Level-1C products don't have SCL band!
                      Example: S2A_MSIL2A_20220101T123456_..._.zip

    Returns:
        Binary mask array where:
        - 1 = Clear pixel (vegetation, bare soil, water)
        - 0 = Masked pixel (cloud, shadow, snow, etc.)
        Shape: (height, width) matching the 20m resolution bands
        Returns None if extraction fails or SCL band not found

    Example:
        >>> mask = extract_cloud_mask(s2_l2a_file)
        >>> print(f"Clear pixels: {mask.sum() / mask.size * 100:.1f}%")
        >>> # Apply mask to RGB image
        >>> rgb_masked = rgb_image.copy()
        >>> rgb_masked[mask == 0] = 0  # Set cloudy pixels to black
    """
    try:
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_path = Path(temp_dir)

            # Extract ZIP file
            with zipfile.ZipFile(zip_file_path, "r") as zip_ref:
                zip_ref.extractall(temp_path)

            # Find SAFE directory
            safe_dirs = list(temp_path.glob("*.SAFE"))
            if not safe_dirs:
                print(f"No SAFE directory found in {zip_file_path.name}")
                return None

            safe_dir = safe_dirs[0]

            # Check if this is a Level-2A product (has SCL band)
            # Level-1C products don't have SCL
            if "MSIL1C" in safe_dir.name:
                print(
                    f"Warning: {zip_file_path.name} is Level-1C (no SCL band). "
                    "Cloud masking requires Level-2A products."
                )
                return None

            # Find IMG_DATA directory
            img_data_dir = safe_dir / "GRANULE"
            granule_dirs = list(img_data_dir.glob("*"))

            if not granule_dirs:
                print(f"No granule directories found in {zip_file_path.name}")
                return None

            granule_dir = granule_dirs[0]

            # SCL band is in IMG_DATA/R20m/ subdirectory (20m resolution)
            img_dir_20m = granule_dir / "IMG_DATA" / "R20m"
            if not img_dir_20m.exists():
                # Try alternative structure (older products)
                img_dir_20m = granule_dir / "IMG_DATA"

            # Find SCL band file
            # Naming pattern: T31UGQ_20220101T123456_SCL_20m.jp2
            scl_patterns = [
                "*_SCL_20m.jp2",  # Standard pattern
                "*_SCL.jp2",  # Alternative pattern
                "*SCL*.jp2",  # Fallback pattern
            ]

            scl_file = None
            for pattern in scl_patterns:
                scl_matches = list(img_dir_20m.glob(pattern))
                if scl_matches:
                    scl_file = scl_matches[0]
                    break

            if scl_file is None:
                print(f"SCL band not found in {zip_file_path.name}")
                print(f"Available files: {list(img_dir_20m.glob('*.jp2'))}")
                return None

            # Read SCL band
            with rasterio.open(scl_file) as src:
                scl_data = src.read(1)  # Read first (and only) band

            # Create binary mask based on SCL classification
            # Clear pixels: vegetation (4), not vegetated (5), water (6)
            # These are the classes where we can see the ground clearly
            clear_classes = [4, 5, 6]

            # Initialize mask as all zeros (all masked)
            mask = np.zeros_like(scl_data, dtype=np.uint8)

            # Set clear pixels to 1
            for clear_class in clear_classes:
                mask[scl_data == clear_class] = 1

            # Calculate cloud coverage statistics for user feedback
            total_pixels = mask.size
            clear_pixels = mask.sum()
            cloud_coverage = (1 - clear_pixels / total_pixels) * 100

            print(f"Cloud coverage: {cloud_coverage:.1f}% (based on SCL classification)")

            return mask

    except Exception as e:
        print(f"Error extracting cloud mask from {zip_file_path.name}: {e}")
        import traceback

        traceback.print_exc()
        return None


def apply_cloud_mask_to_image(
    image_array: np.ndarray, cloud_mask: np.ndarray, fill_value: float = 0.0
) -> np.ndarray:
    """Apply cloud mask to an image array.

    This function sets cloudy pixels to a fill value (typically 0 or NaN).

    Args:
        image_array: Image array to mask, shape (H, W) or (H, W, C)
        cloud_mask: Binary mask where 1=clear, 0=cloudy, shape (H, W)
        fill_value: Value to use for masked pixels (0.0 for black, np.nan for NaN)

    Returns:
        Masked image array with same shape as input

    Example:
        >>> rgb_masked = apply_cloud_mask_to_image(rgb_array, cloud_mask, fill_value=0.0)
        >>> # Or use NaN for numerical analysis
        >>> rgb_masked = apply_cloud_mask_to_image(rgb_array, cloud_mask, fill_value=np.nan)
    """
    # Create a copy to avoid modifying original
    masked_image = image_array.copy()

    # Handle different array dimensions
    if image_array.ndim == 2:
        # Single band image (H, W)
        masked_image[cloud_mask == 0] = fill_value
    elif image_array.ndim == 3:
        # Multi-band image (H, W, C)
        # Broadcast mask across all channels
        masked_image[cloud_mask == 0, :] = fill_value
    else:
        raise ValueError(f"Unsupported image dimensions: {image_array.ndim}")

    return masked_image


def assess_s2_quality(zip_file_path: Path) -> dict:
    """Assess overall quality of Sentinel-2 product.

    This function provides a comprehensive quality assessment of an S2 product,
    including cloud coverage, data completeness, and an overall usability score.

    WHAT IT ASSESSES:
    1. Cloud coverage: Percentage of pixels obscured by clouds/shadows
    2. Data completeness: Whether all expected bands are present
    3. Overall score: Combined metric (0-1) indicating product quality
    4. Usability: Boolean recommendation on whether to use this product

    QUALITY THRESHOLDS:
    - Excellent: < 10% cloud cover (score > 0.9)
    - Good: 10-30% cloud cover (score 0.7-0.9)
    - Fair: 30-50% cloud cover (score 0.5-0.7)
    - Poor: > 50% cloud cover (score < 0.5)

    Args:
        zip_file_path: Path to Sentinel-2 ZIP file (Level-2A preferred for SCL band)

    Returns:
        Dictionary with quality metrics:
        {
            "overall_score": float,      # 0-1, higher is better
            "cloud_coverage": float,     # Percentage (0-100)
            "data_completeness": float,  # Percentage (0-100)
            "usable": bool,              # True if quality is acceptable
            "quality_level": str,        # "excellent", "good", "fair", "poor"
            "notes": list[str]           # Any warnings or issues
        }

    Example:
        >>> quality = assess_s2_quality(s2_file)
        >>> if quality["usable"]:
        ...     print(f"Good quality: {quality['overall_score']:.2f}")
        ...     process_image(s2_file)
        >>> else:
        ...     print(f"Poor quality: {quality['cloud_coverage']:.1f}% clouds")
    """
    notes = []

    # Extract cloud mask
    cloud_mask = extract_cloud_mask(zip_file_path)

    if cloud_mask is None:
        # Could not extract cloud mask (Level-1C or error)
        notes.append("Cloud mask extraction failed - may be Level-1C product")
        return {
            "overall_score": 0.5,  # Neutral score when we can't assess
            "cloud_coverage": None,
            "data_completeness": 100.0,  # Assume complete if file exists
            "usable": True,  # Still usable, just can't assess clouds
            "quality_level": "unknown",
            "notes": notes,
        }

    # Calculate cloud coverage
    total_pixels = cloud_mask.size
    clear_pixels = cloud_mask.sum()
    cloud_coverage = (1 - clear_pixels / total_pixels) * 100

    # Data completeness (simplified - just check if we got a mask)
    # In a full implementation, would check for all expected bands
    data_completeness = 100.0

    # Calculate overall score
    # Score is primarily based on cloud coverage
    # 0% clouds = 1.0 score, 100% clouds = 0.0 score
    cloud_score = 1.0 - (cloud_coverage / 100.0)

    # Overall score combines cloud score with data completeness
    overall_score = cloud_score * (data_completeness / 100.0)

    # Determine quality level
    if cloud_coverage < 10:
        quality_level = "excellent"
    elif cloud_coverage < 30:
        quality_level = "good"
    elif cloud_coverage < 50:
        quality_level = "fair"
    else:
        quality_level = "poor"

    # Determine usability (threshold at 50% cloud cover)
    usable = cloud_coverage < 50.0

    if cloud_coverage > 30:
        notes.append(f"High cloud coverage: {cloud_coverage:.1f}%")

    return {
        "overall_score": overall_score,
        "cloud_coverage": cloud_coverage,
        "data_completeness": data_completeness,
        "usable": usable,
        "quality_level": quality_level,
        "notes": notes,
    }


def assess_s1_quality(zip_file_path: Path) -> dict:
    """Assess overall quality of Sentinel-1 SAR product.

    This function provides a quality assessment of an S1 SAR product.
    SAR data doesn't have clouds, but can have other quality issues.

    WHAT IT ASSESSES:
    1. Data completeness: Whether all expected polarizations are present
    2. File integrity: Whether the ZIP file is valid and complete
    3. Overall score: Combined metric (0-1) indicating product quality
    4. Usability: Boolean recommendation on whether to use this product

    SAR QUALITY CONSIDERATIONS:
    - SAR doesn't have cloud issues (works through clouds)
    - Main issues: missing bursts, calibration problems, acquisition gaps
    - For now, we do basic checks; advanced checks would require reading data

    Args:
        zip_file_path: Path to Sentinel-1 ZIP file (SAFE format)

    Returns:
        Dictionary with quality metrics:
        {
            "overall_score": float,      # 0-1, higher is better
            "data_completeness": float,  # Percentage (0-100)
            "usable": bool,              # True if quality is acceptable
            "quality_level": str,        # "excellent", "good", "fair", "poor"
            "notes": list[str]           # Any warnings or issues
        }

    Example:
        >>> quality = assess_s1_quality(s1_file)
        >>> if quality["usable"]:
        ...     print(f"Good quality SAR: {quality['overall_score']:.2f}")
        ...     process_sar(s1_file)
    """
    notes = []

    try:
        # Check if ZIP file is valid
        with zipfile.ZipFile(zip_file_path, "r") as zip_ref:
            # Test ZIP integrity
            bad_file = zip_ref.testzip()
            if bad_file:
                notes.append(f"Corrupted file in ZIP: {bad_file}")
                return {
                    "overall_score": 0.0,
                    "data_completeness": 0.0,
                    "usable": False,
                    "quality_level": "poor",
                    "notes": notes,
                }

            # Check for expected files
            file_list = zip_ref.namelist()

            # Look for measurement files (actual SAR data)
            measurement_files = [
                f for f in file_list if "/measurement/" in f and f.endswith(".tiff")
            ]

            if not measurement_files:
                notes.append("No measurement files found")
                data_completeness = 0.0
            else:
                # Expect 2 polarizations (VV and VH) for IW mode
                # Some products may have only 1 polarization
                expected_pols = 2
                actual_pols = len(measurement_files)
                data_completeness = min(100.0, (actual_pols / expected_pols) * 100.0)

                if actual_pols < expected_pols:
                    notes.append(
                        f"Only {actual_pols} polarization(s) found (expected {expected_pols})"
                    )

            # Check for manifest file
            manifest_files = [f for f in file_list if "manifest.safe" in f.lower()]
            if not manifest_files:
                notes.append("Manifest file missing")
                data_completeness *= 0.9  # Reduce score

        # Calculate overall score
        # For SAR, score is primarily based on data completeness
        overall_score = data_completeness / 100.0

        # Determine quality level
        if data_completeness >= 95:
            quality_level = "excellent"
        elif data_completeness >= 80:
            quality_level = "good"
        elif data_completeness >= 60:
            quality_level = "fair"
        else:
            quality_level = "poor"

        # Determine usability (threshold at 60% completeness)
        usable = data_completeness >= 60.0

        return {
            "overall_score": overall_score,
            "data_completeness": data_completeness,
            "usable": usable,
            "quality_level": quality_level,
            "notes": notes,
        }

    except zipfile.BadZipFile:
        notes.append("Invalid or corrupted ZIP file")
        return {
            "overall_score": 0.0,
            "data_completeness": 0.0,
            "usable": False,
            "quality_level": "poor",
            "notes": notes,
        }
    except Exception as e:
        notes.append(f"Error assessing quality: {str(e)}")
        return {
            "overall_score": 0.0,
            "data_completeness": 0.0,
            "usable": False,
            "quality_level": "poor",
            "notes": notes,
        }
